{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ordinary differential equation model with inference of point estimates using optimization\nSimon Frost (@sdwfrost), 2020-04-27\n\n## Introduction\n\nThe classical ODE version of the SIR model is:\n\n- Deterministic\n- Continuous in time\n- Continuous in state\n\nIn this notebook, we try to infer the parameter values from a simulated dataset.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using DifferentialEquations\nusing SimpleDiffEq\nusing DiffEqSensitivity\nusing Random\nusing Distributions\nusing DiffEqParamEstim\nusing Plots"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nThe following function provides the derivatives of the model, which it changes in-place. State variables and parameters are unpacked from `u` and `p`; this incurs a slight performance hit, but makes the equations much easier to read.\n\nA variable is included for the cumulative number of infections, $C$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ode!(du,u,p,t)\n    (S,I,R,C) = u\n    (β,c,γ) = p\n    N = S+I+R\n    infection = β*c*I/N*S\n    recovery = γ*I\n    @inbounds begin\n        du[1] = -infection\n        du[2] = infection - recovery\n        du[3] = recovery\n        du[4] = infection\n    end\n    nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time domain\n\nWe set the timespan for simulations, `tspan`, initial conditions, `u0`, and parameter values, `p` (which are unpacked above as `[β,γ]`)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "δt = 1.0\ntmax = 40.0\ntspan = (0.0,tmax)\nobstimes = 1.0:1.0:tmax;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial conditions"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "u0 = [990.0,10.0,0.0,0.0]; # S,I.R,Y"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter values"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p = [0.05,10.0,0.25]; # β,c,γ"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prob_ode = ODEProblem(sir_ode!,u0,tspan,p)\nsol_ode = solve(prob_ode,Tsit5(),saveat=δt);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating data\n\nThe cumulative counts are extracted."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "out = Array(sol_ode)\nC = out[4,:];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new cases per day are calculated from the cumulative counts."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "X = C[2:end] .- C[1:(end-1)];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the ODE system is deterministic, we can add measurement error to the counts of new cases. Here, a Poisson distribution is used, although a negative binomial could also be used (which would introduce an additional parameter for the variance)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(1234);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Y = rand.(Poisson.(X));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Optim.jl directly"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Optim"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single parameter optimization\n\nThis function calculates the sum of squares for a single parameter fit (β). Note how the original `ODEProblem` is remade using the `remake` function. Like all the loss functions listed here, `Inf` is returned if the number of daily cases is less than or equal to zero."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function ss1(β)\n    prob = remake(prob_ode,u0=[990.0,10.0,0.0,0.0],p=[β,10.0,0.25])\n    sol = solve(prob,Tsit5(),saveat=δt)\n    out = Array(sol)\n    C = out[4,:]\n    X = C[2:end] .- C[1:(end-1)]\n    nonpos = sum(X .<= 0)\n    if nonpos > 0\n        return Inf\n    end\n    return(sum((X .- Y) .^2))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimisation routines typically *minimise* functions, so for maximum likelihood estimates, we have to define the *negative* log-likelihood - here, for a single parameter, β."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function nll1(β)\n    prob = remake(prob_ode,u0=[990.0,10.0,0.0,0.0],p=[β,10.0,0.25])\n    sol = solve(prob,Tsit5(),saveat=δt)\n    out = Array(sol)\n    C = out[4,:]\n    X = C[2:end] .- C[1:(end-1)]\n    nonpos = sum(X .<= 0)\n    if nonpos > 0\n        return Inf\n    end\n    -sum(logpdf.(Poisson.(X),Y))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this model, β is positive and (through the meaning of the parameter) bounded between 0 and 1. For point estimates, we could use constrained optimisation, or transform β to an unconstrained scale. Here is the first approach, defining the bounds and initial values for optimization."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "lower1 = 0.0\nupper1 = 1.0\ninitial_x1 = 0.1;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model fit using sum of squares. The output isn't suppressed, as the output of the outcome of the optimisation, such as whether it has converged, is important."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "opt1_ss = Optim.optimize(ss1,lower1,upper1)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model fit using (negative) log likelihood."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "opt1_nll = Optim.optimize(nll1,lower1,upper1)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiparameter optimization\n\nMultiple parameters are handled in the cost function using an array argument. Firstly, sum of squares."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function ss2(x)\n    (i0,β) = x\n    I = i0*1000.0\n    prob = remake(prob_ode,u0=[1000.0-I,I,0.0,0.0],p=[β,10.0,0.25])\n    sol = solve(prob,Tsit5(),saveat=δt)\n    out = Array(sol)\n    C = out[4,:]\n    X = C[2:end] .- C[1:(end-1)]\n    nonpos = sum(X .<= 0)\n    if nonpos > 0\n        return Inf\n    end\n    return(sum((X .- Y) .^2))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondly, negative log-likelihood."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function nll2(x)\n    (i0,β) = x\n    I = i0*1000.0\n    prob = remake(prob_ode,u0=[1000.0-I,I,0.0,0.0],p=[β,10.0,0.25])\n    sol = solve(prob,Tsit5(),saveat=δt)\n    out = Array(sol)\n    C = out[4,:]\n    X = C[2:end] .- C[1:(end-1)]\n    nonpos = sum(X .<= 0)\n    if nonpos > 0\n        return Inf\n    end\n    -sum(logpdf.(Poisson.(X),Y))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two-parameter lower and upper bounds and initial conditions."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "lower2 = [0.0,0.0]\nupper2 = [1.0,1.0]\ninitial_x2 = [0.01,0.1];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "opt2_ss = Optim.optimize(ss2,lower2,upper2,initial_x2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "opt2_nll = Optim.optimize(nll2,lower2,upper2,initial_x2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using DiffEqParamEstim\n\nThe advantage of using a framework such as DiffEqParamEstim is that a number of different frameworks can be employed easily. Firstly, the loss function is defined."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function loss_function(sol)\n    out = Array(sol)\n    C = out[4,:]\n    X = C[2:end] .- C[1:(end-1)]\n    nonpos = sum(X .<= 0)\n    if nonpos > 0\n        return Inf\n    end\n    -sum(logpdf.(Poisson.(X),Y))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondly, a function that generates the `Problem` to be solved."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prob_generator = (prob,q) -> remake(prob,\n    u0=[1000.0-(q[1]*1000),q[1]*1000,0.0,0.0],\n    p=[q[2],10.0,0.25]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function and the problem generator then get combined to build the objective function."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cost_function = build_loss_objective(prob_ode,\n    Tsit5(),\n    loss_function,\n    saveat=δt,\n    prob_generator = prob_generator,\n    maxiters=100,\n    verbose=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optim interface\n\nThe resulting cost function can be passed to `Optim.jl` as before."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "opt_pe1 = Optim.optimize(cost_function,lower2,upper2,initial_x2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NLopt interface\n\nThe same function can also be passed to `NLopt.jl`. For some reason, this reaches the maximum number of evaluations."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using NLopt\nopt = Opt(:LD_MMA, 2)\nopt.lower_bounds = lower2\nopt.upper_bounds = upper2\nopt.min_objective = cost_function\nopt.maxeval = 10000\n(minf,minx,ret) = NLopt.optimize(opt,initial_x2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BlackBoxOptim interface\n\nWe can also use `BlackBoxOptim.jl`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using BlackBoxOptim\nbound1 = Tuple{Float64, Float64}[(0.0,1.0),(0.0, 1.0)]\nresult = bboptimize(cost_function;SearchRange = bound1, MaxSteps = 1e4)"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.5.4"
    },
    "kernelspec": {
      "name": "julia-1.5",
      "display_name": "Julia 1.5.4",
      "language": "julia"
    }
  },
  "nbformat": 4
}
