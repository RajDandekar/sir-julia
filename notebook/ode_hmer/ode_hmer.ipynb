{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# History matching of an ordinary differential equation model using a Bayes linear model emulator\nSimon Frost (@sdwfrost), 2022-04-29\n\n## Introduction\n\nThis tutorial fits a [Bayes linear](https://en.wikipedia.org/wiki/Bayes_linear_statistic) emulator to the final size of an SIR epidemic, and uses the output of the emulator in order to rule out regions of parameter space that are implausible given an 'observed' final size. This uses the R package [hmer](https://github.com/andy-iskauskas/hmer) for the emulator and history matching, with [RCall.jl](https://github.com/JuliaInterop/RCall.jl) used to handle interoperability between Julia and R.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq\nusing DiffEqCallbacks\nusing Surrogates\nusing DataFrames\nusing RCall\nusing Random\nusing Plots;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now import the R package `hmer`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"library(hmer)\";"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For reproducibility, we set the Julia random seed and the R random seed."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(123)\nR\"set.seed(123)\";"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nThis is the standard ODE model widely used in this repository, with the exception that we collapse infectivity, the (constant) population size, N, and the contact rate into a single parameter, β."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ode!(du,u,p,t)\n    (S,I,R) = u\n    (β,γ) = p\n    @inbounds begin\n        du[1] = -β*S*I\n        du[2] = β*S*I - γ*I\n        du[3] = γ*I\n    end\n    nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time domain\n\nWe set the maximum time to be high as we will stop the simulation via a callback."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "tmax = 10000.0\ntspan = (0.0,tmax)\nδt = 1.0;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial conditions\n\nWe need to run the model for lots of initial conditions and parameter values."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "n_train = 50 # Number of training samples\nn_test = 1000; # Number of test samples"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We specify lower (`lb`) and upper (`ub`) bounds for each parameter."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Parameters are β, γ\nlb = [0.00005, 0.1]\nub = [0.001, 1.0];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the model\n\nOur simulation function will make use of a pre-defined `ODEProblem`, which we define here along with default parameter values."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N = 1000.0\nu0 = [990.0,10.0,0.0]\np = [0.0005,0.25]\nprob_ode = ODEProblem(sir_ode!,u0,tspan,p);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a surrogate model\n\nWe start by sampling values of β between the lower and upper bounds using Latin hypercube sampling (via Surrogates.jl), which will give more uniform coverage than a uniform sample given the low number of initial points."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sampler = LatinHypercubeSample();"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "θ = Surrogates.sample(n_train,lb,ub,sampler);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider a logit-transformed final size obtained by running the model until it reaches steady state."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "logit = (x) -> log(x/(1-x))\ninvlogit = (x) -> exp(x)/(exp(x)+1.0)\ncb_ss = TerminateSteadyState()\nlogit_final_size = function(z)\n  prob = remake(prob_ode;p=z)\n  sol = solve(prob, ROS34PW3(),callback=cb_ss)\n  fsp = sol[end][3]/N\n  logit(fsp)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now calculate the logit final size as follows."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "lfs = logit_final_size.(θ);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create a dataframe with the input values and the output. R does not like the use of unicode symbols out of the box, so we write `β` as `b` and `γ` as `g`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "training_df = DataFrame(θ)\nrename!(training_df,[\"b\",\"g\"])\ntraining_df[!,:lfs] = lfs;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `emulator_from_data` function in `hmer` requires a named list for the lower and upper bounds of the parameters, as well as the name of the output(s) in the dataframe."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "input_ranges = Dict(:b => [lb[1], ub[1]], :g => [lb[2], ub[2]])\noutput_names = [\"lfs\"];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We copy over the three inputs to R."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@rput training_df\n@rput output_names\n@rput input_ranges;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now fit the emulator."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"emulator <- emulator_from_data(training_df, output_names, input_ranges)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have fitted an emulator, we can evaluate on a larger set of test parameters."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "θ_test = sample(n_test,lb,ub,sampler)\nlfs_test = logit_final_size.(θ_test);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "These parameter values are then converted to a dataframe in order to be used in `hmer`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "test_df = DataFrame(θ_test)\nrename!(test_df,[\"b\",\"g\"])\ntest_df[!,:lfs] = lfs_test\n@rput test_df; # copy to R"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of `emulator_from_data` is an object where for each output (here, `lfs`), there are functions `get_exp` to get the mean and `get_cov` to get the (co)variance(s)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"lfs_test_pred <- list()\"\nR\"lfs_test_pred$mean <- emulator$lfs$get_exp(test_df)\"\nR\"lfs_test_pred$unc <- emulator$lfs$get_cov(test_df)\"\n@rget lfs_test_pred;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output gives a reasonable approximation of the model output."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "scatter(invlogit.(lfs_test),\n        invlogit.(lfs_test_pred[:mean]),\n        xlabel = \"Model final size\",\n        ylabel = \"Surrogate final size\",\n        legend = false,\n        title = \"Test set\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To gain further insights, we can fix one of the parameters while sweeping over a fine grid of the other. Firstly, we fix the recovery rate γ and vary β."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "β_grid = collect(lb[1]:0.00001:ub[1])\nθ_eval = [(βᵢ,0.25) for βᵢ in β_grid]\neval_df = DataFrame(θ_eval)\nrename!(eval_df,[\"b\",\"g\"])\n@rput eval_df\nR\"lfs_eval <- list()\"\nR\"lfs_eval$mean <- emulator$lfs$get_exp(eval_df)\"\nR\"lfs_eval$unc <- emulator$lfs$get_cov(eval_df)\"\n@rget lfs_eval\nfs_eval = invlogit.(lfs_eval[:mean])\nfs_eval_uc = invlogit.(lfs_eval[:mean] .+ 1.96 .* sqrt.(lfs_eval[:unc]))\nfs_eval_lc = invlogit.(lfs_eval[:mean] .- 1.96 .* sqrt.(lfs_eval[:unc]))\nplot(β_grid,\n     fs_eval,\n     xlabel = \"Infectivity parameter, β\",\n     ylabel = \"Final size\",\n     label = \"Model\")\nplot!(β_grid,\n      invlogit.(logit_final_size.(θ_eval)),\n      ribbon = (fs_eval .- fs_eval_lc, fs_eval_uc - fs_eval),\n      label = \"Surrogate\",\n      legend = :right)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that in the above, for a range of values of β, the true value of the model lies outside of the uncertainty range of the emulator.\n\nNow, we fix β and vary the recovery rate, γ."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "γ_grid = collect(lb[2]:0.001:ub[2])\nθ_eval = [(0.001,γᵢ) for γᵢ in γ_grid]\neval_df = DataFrame(θ_eval)\nrename!(eval_df,[\"b\",\"g\"])\n@rput eval_df\nR\"lfs_eval <- list()\"\nR\"lfs_eval$mean <- emulator$lfs$get_exp(eval_df)\"\nR\"lfs_eval$unc <- emulator$lfs$get_cov(eval_df)\"\n@rget lfs_eval\nfs_eval = invlogit.(lfs_eval[:mean])\nfs_eval_uc = invlogit.(lfs_eval[:mean] .+ 1.96 .* sqrt.(lfs_eval[:unc]))\nfs_eval_lc = invlogit.(lfs_eval[:mean] .- 1.96 .* sqrt.(lfs_eval[:unc]))\nplot(γ_grid,\n     fs_eval,\n     xlabel = \"Recovery rate, γ\",\n     ylabel = \"Final size\",\n     label = \"Model\")\nplot!(γ_grid,\n      invlogit.(logit_final_size.(θ_eval)),\n      ribbon = (fs_eval .- fs_eval_lc, fs_eval_uc - fs_eval),\n      label = \"Surrogate\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## History matching\n\n[History matching](https://mogp-emulator.readthedocs.io/en/latest/methods/thread/ThreadGenericHistoryMatching.html) is an approach used to learn about the inputs to a model using observations of the real system. The history matching process typically involves the use of expectations and variances of emulators, such as those generated by the Bayes linear emulator above. History matching seeks to identify regions of the input space that would give rise to acceptable matches between model output and observed data. 'Implausible' model outputs that are very different from the observed data are discarded, leaving a 'not ruled out yet' (NROY) set of input parameters.\n\nFirstly, we need some observations. We'll take the final size at the default parameter values `p` as our observation, and consider final sizes within 1% as acceptable."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "obs = logit_final_size(p)\nobs_lc = logit(0.99*invlogit(obs))\nobs_uc = logit(1.01*invlogit(obs))\ntarget = Dict(:lfs => [obs_lc, obs_uc])\n@rput target"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now use `generate_new_runs` to generate new parameter values usin the emulator that are not ruled out yet - in the below, an implausibility cutoff of 3 is used, and `n_test` parameter sets are evaluated, generated using Latin Hypercube sampling."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"new_points <- generate_new_runs(emulator, $n_test, target, method = 'lhs', cutoff = 3)\"\n@rget new_points;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A plot of the results shows that the true values of the parameters are within the bounds of the not ruled out yet values."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "l = @layout [a b]\npl1 = histogram(new_points[!,:b],legend=false,xlim=(lb[1],ub[1]),bins=lb[1]:0.00005:ub[1],title=\"NROY values for β\")\nvline!(pl1,[p[1]])\npl2 = histogram(new_points[!,:g],legend=false,xlim=(lb[2],ub[2]),bins=lb[2]:0.05:ub[2],title=\"NROY values for γ\")\nvline!(pl2,[p[2]])\nplot(pl1, pl2, layout = l)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, an iterative approach would be taken where the non-implausible parameter sets are used to generate a new set of parameter samples, from which a new emulator is fitted, and the new set of parameter values are filtered on the basis of the implausibility measure. The [vignettes for `hmer`](https://cran.r-project.org/web/packages/hmer/index.html) provide more detailed background on this."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.3"
    },
    "kernelspec": {
      "name": "julia-1.6",
      "display_name": "Julia 1.6.3",
      "language": "julia"
    }
  },
  "nbformat": 4
}
