{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Universal differential equation\nSimon Frost (@sdwfrost), 2022-03-28\n\n## Introduction\n\n[Universal differential equations](https://arxiv.org/abs/2001.04385) combine neural networks with differential equation models, in order to combine domain-specific knowledge with data-driven insights. In this tutorial, we use a neural network to model the force of infection without making prior assumptions of the functional form, using noisy data of the number of new infections per day.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq\nusing Distributions\nusing DiffEqFlux, Flux\nusing Random\nusing Plots;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(123);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ode(u,p,t)\n    (S,I,C) = u\n    (β,γ) = p\n    dS = -β*S*I\n    dI = β*S*I - γ*I\n    dC = β*S*I\n    [dS,dI,dC]\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "solver = RadauIIA3();"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the model is in terms of proportions of susceptible, infected, and recovered individuals, we define the total population size, `N`, so we can generate random data of the number of new cases per day."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N = 1000.0\np = [0.5,0.25]\nu0 = [0.99, 0.01, 0.0]\ntspan = (0., 40.)\nδt = 1;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solving the true model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_prob = ODEProblem(sir_ode, u0, tspan, p)\nsir_sol = solve(sir_prob, solver, saveat = δt);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(sir_sol,\n     xlabel = \"Time\",\n     ylabel = \"Proportion\",\n     labels = [\"S\" \"I\" \"R\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating 'observed' data\n\nWe define the time over which the training data are generated, and generate noisy data corresponding to the number of new cases per day."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "train_time = 30.0\ntsdata = Array(sir_sol(0:δt:train_time))\ncdata = diff(tsdata[3,:])\nnoisy_data = rand.(Poisson.(N .* cdata));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(1:δt:train_time, N .* cdata,\n     xlabel = \"Time\",\n     ylabel = \"New cases per day\",\n     label = \"True value\")\nscatter!(1:δt:train_time, noisy_data, label=\"Data\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Single layer network\n\nWe start by defining a single neural network layer with one input and one output and no bias parameter, which is the true relationship between `i` and the force of infection."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "foi1 = FastDense(1, 1, relu, bias=false)\np1_ = Float64.(initial_params(foi1))\nlength(p1_)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following model allows one to change the function used to describe the force of infection, i.e. the per-capita rate at which susceptible individuals become infected."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ude(u,p_,t,foi)\n    S,I,C = u\n    β,γ = p\n    λ = foi([I],p_)[1]\n    dS = -λ*S\n    dI = λ*S - γ*I\n    dC = λ*S\n    [dS, dI, dC]\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "tspan_train = (0,train_time)\nsir_ude1 = (u,p_,t) -> sir_ude(u,p_,t,foi1)\nprob_ude1 = ODEProblem(sir_ude1,\n                      u0,\n                      tspan_train,\n                      p1_);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fit this model, we first need to define a function that predicts the outcome given a set of parameters."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function predict(θ, prob)\n    Array(solve(prob,\n                solver;\n                u0 = u0,\n                p = θ,\n                saveat = δt,\n                sensealg = InterpolatingAdjoint(autojacvec=ReverseDiffVJP())))\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondly, we define a loss function that uses this predict function to calculate the loss between the predicted data and the true data. We employ a Poisson loss, as we are comparing our model against counts of new cases."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function loss(θ, prob)\n    pred = predict(θ, prob)\n    cpred = abs.(N*diff(pred[3,:]))\n    Flux.poisson_loss(cpred, float.(noisy_data)), cpred\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run this function once to make sure it is precompiled."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "loss(prob_ude1.p, prob_ude1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To keep track of the running of the model, we store the losses in a `Vector` and use a callback to report on the model fit every 10 epochs."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "const losses1 = []\ncallback1 = function (p, l, pred)\n    push!(losses1, l)\n    numloss = length(losses1)\n    if numloss % 10 == 0\n        display(\"Epoch: \" * string(numloss) * \" Loss: \" * string(l))\n    end\n    return false\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "res_ude1 = DiffEqFlux.sciml_train((θ)->loss(θ,prob_ude1),\n                                  p1_,\n                                  cb=callback1);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fitted parameter in this model corresponds to the infectivity parameter, `β`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "res_ude1.minimizer, losses1[end]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is fast to converge to an optimum due to the small number of trainable parameters."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(losses1, xaxis = :log, xlabel = \"Iterations\", ylabel = \"Loss\", legend=false)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fitted model provides a good fit to all the states, despite only being trained on a noisy representation of the number of new infections."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prob_ude1_fit = ODEProblem(sir_ude1, u0, tspan, res_ude1.minimizer)\nsol_ude1_fit = solve(prob_ude1_fit, solver, saveat = δt)\nscatter(sir_sol, label=[\"True Susceptible\" \"True Infected\" \"True Recovered\"],title=\"Fitted true model\")\nplot!(sol_ude1_fit, label=[\"Estimated Susceptible\" \"Estimated Infected\" \"Estimated Recovered\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plots the relationship between `i` and the force of infection, `λ`, which shows a good match."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Imax = maximum(tsdata[2,:])\nIgrid = 0:0.01:0.5\nλ = [foi1([I],res_ude1.minimizer)[1] for I in Igrid]\nscatter(Igrid,λ,xlabel=\"Proportion of population infected, I\",ylab=\"Force of infection, λ\",label=\"Neural network prediction\")\nPlots.abline!(p[1],0,label=\"True value\")\nPlots.vline!([Imax],label=\"Upper bound of training data\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple layer network\n\nIn the absence of prior knowledge, we use a neural network with multiple layers."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(1234)\nnhidden = 4\nfoi2 = FastChain(FastDense(1, nhidden, relu),\n                     FastDense(nhidden, nhidden, relu),\n                     FastDense(nhidden, 1, relu))\np2_ = Float64.(initial_params(foi2))\nlength(p2_)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wrap this neural network in a new `ODEProblem`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sir_ude2 = (u,p_,t) -> sir_ude(u,p_,t,foi2)\nprob_ude2 = ODEProblem(sir_ude2,\n                      u0,\n                      tspan_train,\n                      p2_);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a new data structure to store the losses from the fitting of this more complex model."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "const losses2 = []\ncallback2 = function (p, l, pred)\n    push!(losses2, l)\n    numloss = length(losses2)\n    if numloss % 10 == 0\n        display(\"Epoch: \" * string(numloss) * \" Loss: \" * string(l))\n    end\n    return false\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "res_ude2 = DiffEqFlux.sciml_train((θ)->loss(θ,prob_ude2),\n                                  p2_,\n                                  cb = callback2);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the 'true' model and the more flexible model give a comparable fit to the data in terms of the loss function."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "losses1[end],losses2[end]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consistent with this, the multilayer model gives a good fit when plotted alongside the data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prob_ude2_fit = ODEProblem(sir_ude2, u0, tspan, res_ude2.minimizer)\nsol_ude2_fit = solve(prob_ude2_fit, solver, saveat = δt)\nscatter(sir_sol, label=[\"True Susceptible\" \"True Infected\" \"True Recovered\"],title=\"Fitted UDE model\")\nplot!(sol_ude2_fit, label=[\"Estimated Susceptible\" \"Estimated Infected\" \"Estimated Recovered\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the inferred functional relationship between the proportion of infected individuals and the force of infection."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "λ = [foi2([I],res_ude2.minimizer)[1] for I in Igrid]\nscatter(Igrid, λ, xlabel=\"Proportion of population infected, i\", ylab=\"Force of infection, λ\", label=\"Neural network prediction\")\nPlots.abline!(p[1], 0,label=\"True value\")\nPlots.vline!([Imax], label=\"Upper bound of training data\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n\nThe number of new infections per day is sufficient to fit an SIR model assuming the correct functional form for the force of infection. A universal differential equation that uses a multilayer neural network to infer the relationship between the proportion of infected individuals and the force of infection recovers the true relationship, at least for the range of the size of the infected subpopulation seen in the training data. As we would expect that the force of infection would be higher when there are more infected individuals, we could adapt the neural network to reflect a monotonic relationship, either by constraining the neural network, or by introducing a penalty term in the loss function."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.2"
    },
    "kernelspec": {
      "name": "julia-1.6",
      "display_name": "Julia 1.6.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
