{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian melding applied to ordinary differential equation model\nSimon Frost (@sdwfrost), 2022-03-12\n\n## Introduction\n\nBayesian melding is an approach to fit deterministic models, which takes into account uncertainty in both the inputs and the outputs. Following [Poole and Raftery (2000)](https://doi.org/10.1080/01621459.2000.10474324), we define a deterministic model M that maps a set of input parameters θ to a set of outputs ϕ. ψ denotes a set of *quantities of interest* (QoI) that may model inputs, model outputs, or functions of either or both. q₁(θ) is the prior distribution of inputs, q₂(ϕ) is the prior distribution of outputs, L₁(θ)=p(D₁|θ) is the likelihood of the inputs and L₂(ϕ)=p(D₂|ϕ) is the likelihood of the outputs, where D₁ and D₂ represent data. The inputs q₁(θ) and the model M induce a distribution on the outputs, denoted q₁⋆(ϕ). Bayesian synthesis uses logarithmic pooling to combine the information from the model, q₁⋆(ϕ), and the existing prior on the outputs, q₂(ϕ).\n\nA sampling-importance-resampling approach to Bayesian melding proceeds as follows.\n\n1. Draw k samples of θ from q₁(θ) to produce (θ₁,...,θₖ).\n2. Run the model for each value of θ to give ϕᵢ=M(θᵢ).\n3. Estimate the induced prior q₁⋆(ϕ) by applying density estimation techniques to ϕᵢ.\n4. Calculate the importance sampling weights, wᵢ given by (q₂(ϕᵢ)/q₁⋆(ϕᵢ))¹⁻ᵅ × L₁(θᵢ) × L₂(ϕᵢ), where α is the pooling weight. α=0.5 gives equal weights to the induced prior q₁⋆ and the prior q₂.\n5. Sample θᵢ with probability wᵢ to generate n samples.\n\nThis example takes an SIR ODE model and uses Bayesian melding using the final size of the epidemic, with priors on both the infectivity parameter β and the final size.\n\n## Libraries"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq\nusing DiffEqCallbacks\nusing Optim\nusing Random\nusing Distributions\nusing StatsBase\nusing Plots\nusing BenchmarkTools"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transitions\n\nThe following function is a simplified SIR ODE model, in which we combine the infectivity parameter and the contact rate into a single parameter."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_ode!(du,u,p,t)\n    (S,I,R) = u\n    (β,γ) = p\n    N = S+I+R\n    @inbounds begin\n        du[1] = -β*S*I\n        du[2] = β*S*I - γ*I\n        du[3] = γ*I\n    end\n    nothing\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time domain\n\nWe set the timespan for simulations to be high, as we will be using a callback in order to stop the integration early when the system reaches a steady state."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "tmax = 10000.0\ntspan = (0.0,tmax);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks\n\nIf we just wanted the final size, we could use a `SteadyStateProblem` with the `DynamicSS` solver. To get access to the entire solution, we can use a callback instead to stop the simulation when it reaches a steady state."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cb_ss = TerminateSteadyState();"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial conditions and parameter values\n\nWe first set fixed parameters, in this case, the total population size, `N`. In addition, in order to define an `ODEProblem`, we also need a default set of initial conditions, `u`, and parameter values, `p`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N = 1000.0;\nu0 = [990.0,10.0,0.0];\np = [0.0005,0.25]; # β,γ"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "prob_ode = ODEProblem(sir_ode!,u0,tspan,p);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "sol_ode = solve(prob_ode,Tsit5())\nplot(sol_ode(0:1:40.0),\n     xlabel=\"Time\",\n     ylabel=\"Number\",\n     labels=[\"S\" \"I\" \"R\"])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian melding\n\n### Step 1: sampling the prior parameter values, θ\n\nWe assume a uniform prior on β, and sample β across a fine grid."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "lb = 0.00005\nub = 0.001\nδ = 0.0000001;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "θ = lb:δ:ub;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we had different prior information on β, we could sample from a different distribution (e.g. using the `rand` functions from `Distributions.jl`) or generate an additional set of prior weights to use in step 4, below (e.g. using the `pdf` functions from `Distributions.jl`).\n\n### Step 2: simulating the model\n\nWe define the model M(θ) to generate values of ϕ - in this case, the final size of the epidemic as a fraction of the whole population."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "M = function(θ)\n  p = prob_ode.p\n  p[1] = θ\n  prob = remake(prob_ode;p=p)\n  sol = solve(prob, ROS34PW3(),callback=cb_ss)\n  ϕ = sol[end][3]/N\n  ϕ\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "An approximation to the final size (for large population size, N) is given by the solution of the implicit equation ϕ=1-S(0)exp(-R₀ϕ)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Roots\nM_analytic = function(θ)\n  _,γ = prob_ode.p\n  β = θ\n  R₀ = β*N/γ\n  S0 = prob_ode.u0[1]/N\n  f(ϕ) = 1-S0*exp(-R₀*ϕ)-ϕ\n  ϕ = find_zero(f,(0.0,1.0))\n  ϕ\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use this later for improved speed, as shown below."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@benchmark M(p[1])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@benchmark M_analytic(p[1])"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now generate the outputs `ϕ` by applying the model `M` to the vector of inputs `θ` using Julia's `.` syntax."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "ϕ = M.(θ);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this model, the basic reproductive number is given by the expression R₀=βN/γ, which is more easily interpretable than an infectivity parameter β. We compute this and plot the final size against both R₀ and infectivity. Plots.jl does not provide a `twiny` command so [following this StackOverflow post](https://stackoverflow.com/questions/64176617/julia-two-x-axes-for-plot-of-same-data), we add a second x axis."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R₀ = θ*N/p[2];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function twiny(sp::Plots.Subplot)\n    sp[:top_margin] = max(sp[:top_margin], 30Plots.px)\n    plot!(sp.plt, inset = (sp[:subplot_index], bbox(0,0,1,1)))\n    twinsp = sp.plt.subplots[end]\n    twinsp[:xaxis][:mirror] = true\n    twinsp[:background_color_inside] = RGBA{Float64}(0,0,0,0)\n    Plots.link_axes!(sp[:yaxis], twinsp[:yaxis])\n    twinsp\nend\ntwiny(plt::Plots.Plot = current()) = twiny(plt[1]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(θ, ϕ,\n     xlabel=\"Infectivity parameter, β\",\n     ylabel=\"Final size, ϕ\",\n     legend=false)\npl = twiny()\nplot!(pl, R₀, ϕ, xlabel = \"Reproductive number, R₀\", legend = false)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: estimating the probability density of the outputs\n\nThere are multiple packages in Julia that perform nonparametric density estimation. Here, we obtain estimates of the probability density of the induced prior q₁* using four different packages."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using KernelDensity\nk_kd = kde_lscv(ϕ;boundary=(0.0,1.0),kernel=Normal)\nq1star_kd = [pdf(k_kd, ϕᵢ) for ϕᵢ in ϕ];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using KernelDensityEstimate\nk_kde = KernelDensityEstimate.kde!(ϕ)\nq1star_kde = evaluateDualTree(k_kde,ϕ);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using AverageShiftedHistograms\nk_ash = ash(ϕ)\nq1star_ash = [AverageShiftedHistograms.pdf(k_ash,ϕᵢ) for ϕᵢ in ϕ];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using MultiKDE\nk_mkde = KDEUniv(ContinuousDim(), 0.01, ϕ, MultiKDE.gaussian)\nq1star_mkde = [MultiKDE.pdf(k_mkde, ϕᵢ, keep_all=false) for ϕᵢ in ϕ];"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(ϕ,q1star_kd,label=\"KernelDensity\",xlabel=\"Final size\",ylabel=\"Density\")\nplot!(ϕ,q1star_kde,label=\"KernelDensityEstimate\")\nplot!(ϕ,q1star_ash,label=\"AverageShiftedHistograms\")\nplot!(ϕ,q1star_mkde,label=\"MultiKDE\",legend=:top)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: generating importance weights\n\nWe choose geometric weighting (α=0.5) and a prior on the final size of between 5% and 10% of the population. In this simple example, we don't have any data, so the likelihoods are all proportional to 1."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "α = 0.5\nq₂ = Distributions.pdf.(Uniform(0.05,0.1),ϕ)\nL₁(θᵢ) = 1.0\nL₂(ϕᵢ) = 1.0;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For illustration purposes, we will choose one method of density estimation (from `KernelDensity`)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(ϕ,q₂,label=\"Prior on outputs, q₂\")\nplot!(ϕ,q1star_kd,label=\"Induced prior on outputs, q₁*\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "w_kd = (q₂ ./ q1star_kd).^(1-α) .* L₁.(θ) .* L₂.(ϕ);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, on a logarithmic scale."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "lw_kd = (1-α) .* log.(q₂) .- (1-α) .* log.(q1star_kd) .+ log.(L₁.(θ)) .+ log.(L₂.(ϕ));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the other density estimators (and omitting L₁ and L₂ for brevity):"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "w_kde = (q₂ ./ q1star_kde).^(1-α)\nw_ash = (q₂ ./ q1star_ash).^(1-α)\nw_mkde = (q₂ ./ q1star_mkde).^(1-α);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: resampling\n\nSampling with weights can be done using `StatsBase.jl`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(123)\nn = 1000\nπθ = StatsBase.sample(θ, Weights(w_kd),n,replace=true);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the mean and standard deviation of the model inputs after considering a prior on final size."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mean(πθ),std(πθ)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "histogram(πθ,\n          bins=25,\n          legend=false,\n          xlim=(lb,ub),\n          xlabel=\"Infectivity parameter, β\",\n          ylabel=\"Count\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n\nAn important consideration in importance sampling approaches is the *effective sample size* rather than just the actual sample size, `l`, for the final step. Measures of ESS can be obtained from the weights vector, `w`; one common derivation uses the inverse of the sum of the squared normalized weights. From the below, the resampling results in an effective sample size three times lower than the actual sample size, `n`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "w_norm = w_kd ./ sum(w_kd)\ness = 1.0/sum(w_norm .^ 2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other more complex algorithms such as [Incremental Mixture Importance Sampling (IMIS)](https://dx.doi.org/10.1111%2Fj.1541-0420.2010.01399.x) or [Langevin Incrementatl Mixture Importance Sampling (LIMIS)](https://doi.org/10.1007/s11222-017-9747-5) may give better performance when weights are highly variable.\n\nAnother important issue is the choice of nonparametric density estimation method. Below, we use a much finer grid of inputs; to reduce computational time, the analytic approximation is used, with parallel computations through the `ThreadsX` package. We do not evaluate the `KernelDensityEstimate` package, as the bandwidth selection is slow for the increased sample size."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using ThreadsX\nθ_fine = lb:1e-10:ub\n# We use ThreadsX instead of ϕ_fine = M_analytic.(θ_fine)\nϕ_fine = ThreadsX.collect(M_analytic(θᵢ) for θᵢ in θ_fine)\nk_kd_fine = kde_lscv(ϕ_fine;boundary=(0.0,1.0),kernel=Normal)\n#k_kde_fine = KernelDensityEstimate.kde!(ϕ_fine)\nk_ash_fine = ash(ϕ_fine)\nk_mkde_fine = KDEUniv(ContinuousDim(), 0.01, ϕ_fine, MultiKDE.gaussian)\nq1star_kd_fine = [pdf(k_kd_fine, ϕᵢ) for ϕᵢ in ϕ]\n#q1star_kde_fine = evaluateDualTree(k_kde_fine,ϕ_fine)\nq1star_ash_fine = [AverageShiftedHistograms.pdf(k_ash_fine,ϕᵢ) for ϕᵢ in ϕ]\nq1star_mkde_fine = ThreadsX.collect(MultiKDE.pdf(k_mkde_fine, ϕᵢ, keep_all=false) for ϕᵢ in ϕ);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "l = @layout [a; b; c]\npl1 = plot(ϕ,q1star_kd_fine,label=\"KernelDensity fine\",xlabel=\"Final size\",ylabel=\"Density\")\nplot!(pl1,ϕ,q1star_kd,label=\"KernelDensity coarse\")\npl2=plot(ϕ,q1star_ash_fine,label=\"AverageShiftedHistograms fine\")\nplot!(pl2,ϕ,q1star_ash,label=\"AverageShiftedHistograms coarse\")\npl3=plot(ϕ,q1star_mkde,label=\"MultiKDE\")\nplot!(pl3,ϕ,q1star_mkde_fine,label=\"MultiKDE fine\")\nplot(pl1, pl2, pl3, layout=l)"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.2"
    },
    "kernelspec": {
      "name": "julia-1.6",
      "display_name": "Julia 1.6.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
